 (

---

 1 â€“ Setup and load the file

Paste this in the first cell:

import os
import pandas as pd

# === 1) PATH TO YOUR FILE ===
# Adjust this to your actual OneDrive path.
# Example pattern:
# r"C:\Users\YOUR_USER\OneDrive - YOUR BANK\SCU_DataPipeline\01_Raw\RDP Daily BO.xlsx"

file_path = r"C:\Users\YOUR_USER\OneDrive - YOUR BANK\SCU_DataPipeline\01_Raw\RDP Daily BO.xlsx"

if not os.path.exists(file_path):
    raise FileNotFoundError(f"File not found. Check the path:\n{file_path}")

print("âœ… Using file:", file_path)

# === 2) LOAD EXCEL (JUST METADATA FIRST) ===
xls = pd.ExcelFile(file_path)
print("ğŸ“„ Sheet names:", xls.sheet_names)

# For now we'll assume the first sheet is the relevant one.
main_sheet = xls.sheet_names[0]
print("ğŸ“„ Using sheet:", main_sheet)

df = pd.read_excel(file_path, sheet_name=main_sheet)

print("\nâœ… Loaded DataFrame")
print("Shape (rows, columns):", df.shape)

ğŸ”¹ Screenshot 1:
After running this, take a screenshot showing:

sheet names

chosen sheet

shape



---

ğŸ”§ Cell 2 â€“ Show columns and the first 15 rows

print("ğŸ“Œ Columns:")
for i, col in enumerate(df.columns):
    print(f"{i:02d}: {col}")

print("\nğŸ‘€ First 15 rows:")
df.head(15)

ğŸ”¹ Screenshot 2:
Take a clear screenshot showing:

the list of columns

the first 15 rows of data


If all columns donâ€™t fit horizontally, scroll and take 2â€“3 screenshots (left/middle/right).


---

ğŸ”§ Cell 3 â€“ Data types and basic null info

print("ğŸ“Š Data types:")
print(df.dtypes)

print("\nğŸ” Null counts (top 30 columns):")
null_counts = df.isna().sum().sort_values(ascending=False)
print(null_counts.head(30))

ğŸ”¹ Screenshot 3:

data types

null counts


This tells me whatâ€™s numeric, whatâ€™s text, etc.


---

ğŸ”§ Cell 4 â€“ CustomerId and Exposure exploration (you fill in names)

Now you tell Python which columns you believe are CustomerId and Exposure.
If youâ€™re not 100% sure of exposure, list a few candidates.

# ğŸ” EDIT THESE NAMES BASED ON WHAT YOU SEE IN CELL 2
customer_id_col = "CustomerId"      # <-- put exact column name here
exposure_cols   = ["Exposure"]      # <-- or ["Exposure", "Balance", "Limit"] etc.

print("CustomerId column:", customer_id_col)
print("Exposure-related columns:", exposure_cols)

# Safety: check they exist
missing = [c for c in [customer_id_col] + exposure_cols if c not in df.columns]
if missing:
    print("âš ï¸ WARNING: These columns were not found:", missing)
else:
    print("âœ… All specified columns found.")

# Show sample of these columns
cols_to_show = [customer_id_col] + exposure_cols
print("\nğŸ‘€ Sample of CustomerId + exposure columns (first 20 rows):")
df[cols_to_show].head(20)

ğŸ”¹ Screenshot 4:

the printed column names

the sample of CustomerId + exposure columns



---

ğŸ”§ Cell 5 â€“ Basic stats for exposure columns

for col in exposure_cols:
    if col in df.columns:
        print(f"\nğŸ“ˆ Stats for {col}:")
        print(df[col].describe())

ğŸ”¹ Screenshot 5:

describe() output (count, mean, min, max, etc.)



---

ğŸ”§ Cell 6 â€“ How many rows / unique customers / duplicates

if customer_id_col in df.columns:
    total_rows = len(df)
    unique_customers = df[customer_id_col].nunique()
    null_ids = df[customer_id_col].isna().sum()

    print(f"Total rows: {total_rows}")
    print(f"Unique {customer_id_col}: {unique_customers}")
    print(f"Null {customer_id_col}: {null_ids}")

    # Distribution of rows per customer (top 10)
    counts = df[customer_id_col].value_counts()
    print("\nğŸ“Š Distribution of rows per customer (top 10):")
    print(counts.head(10))

    print("\nâ„¹ï¸ Quick summary:")
    print(f"- % of customers with exactly 1 row: {(counts.eq(1).sum() / len(counts)):.2%}")
    print(f"- % of customers with > 1 row: {(counts.gt(1).sum() / len(counts)):.2%}")
else:
    print(f"âš ï¸ Column {customer_id_col} not found. Can't compute per-customer stats.")

